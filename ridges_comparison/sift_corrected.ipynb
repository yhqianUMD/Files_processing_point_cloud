{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71586253-a6b9-4a84-8487-3d8fad5fe935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import rasterio\n",
    "from rasterio.windows import from_bounds\n",
    "from rasterio.warp import reproject, Resampling\n",
    "from skimage import exposure\n",
    "from skimage.feature import SIFT, match_descriptors\n",
    "from skimage.morphology import binary_erosion, footprint_rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d6afdfe-5bfe-4c01-b86e-d4cb87355525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _prepare_dem(img, nodata=-9999.0, min_elev=-5.0):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      proc: float32 image in [0,1] for SIFT\n",
    "      mask: True where invalid (nodata / nan / outlier)\n",
    "    \"\"\"\n",
    "    img = img.astype(np.float32)\n",
    "\n",
    "    mask = (img == nodata) | np.isnan(img) | (img < min_elev)\n",
    "    if np.all(mask):\n",
    "        raise ValueError(\"All pixels are masked (NoData/outliers) in the selected overlap.\")\n",
    "\n",
    "    valid = img[~mask]\n",
    "    valid_mean = np.nanmean(valid)\n",
    "\n",
    "    img_filled = img.copy()\n",
    "    img_filled[mask] = valid_mean\n",
    "\n",
    "    # Robust contrast stretch based on valid pixels only\n",
    "    p2, p98 = np.percentile(valid, (2, 98))\n",
    "    proc = exposure.rescale_intensity(\n",
    "        img_filled, in_range=(p2, p98), out_range=(0.0, 1.0)\n",
    "    ).astype(np.float32)\n",
    "\n",
    "    return proc, mask\n",
    "\n",
    "\n",
    "def _robust_translation_from_matches(src_xy, dst_xy, z=3.5):\n",
    "    \"\"\"\n",
    "    Robust translation estimate using median + MAD filtering.\n",
    "\n",
    "    src_xy, dst_xy: (N,2) arrays in (x,y) coords (col,row)\n",
    "    Returns:\n",
    "      tx_pix, ty_pix, keep_ratio\n",
    "    \"\"\"\n",
    "    d = dst_xy - src_xy  # (N,2)\n",
    "    med = np.median(d, axis=0)\n",
    "\n",
    "    mad = np.median(np.abs(d - med), axis=0) + 1e-6\n",
    "    scale = 1.4826 * mad\n",
    "\n",
    "    keep = (np.abs(d - med) <= z * scale).all(axis=1)\n",
    "    keep_ratio = float(np.mean(keep))\n",
    "\n",
    "    if np.sum(keep) >= 3:\n",
    "        d2 = d[keep]\n",
    "        med2 = np.median(d2, axis=0)\n",
    "        return float(med2[0]), float(med2[1]), keep_ratio\n",
    "\n",
    "    # If too few kept, fall back to raw median\n",
    "    return float(med[0]), float(med[1]), keep_ratio\n",
    "\n",
    "\n",
    "def calculate_drift_sift_translation_only(\n",
    "    path_ref,\n",
    "    path_mov,\n",
    "    nodata=-9999.0,\n",
    "    min_elev=-5.0,\n",
    "    max_ratio=0.8,\n",
    "    erosion_iters=10,\n",
    "    min_matches=8,\n",
    "    debug=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Computes bulk drift between two DEMs (same CRS, e.g., EPSG:3413) using:\n",
    "      1) overlap extraction\n",
    "      2) resample mov DEM onto ref overlap grid\n",
    "      3) SIFT matching\n",
    "      4) robust translation (median + MAD), translation-only\n",
    "\n",
    "    Convention:\n",
    "      We estimate the shift that maps REF -> MOV:\n",
    "        (x_mov, y_mov) â‰ˆ (x_ref + dE, y_ref + dN)\n",
    "\n",
    "    Returns:\n",
    "      tx_pix, ty_pix, dE_m, dN_m, match_count, keep_ratio\n",
    "\n",
    "    Where:\n",
    "      tx_pix, ty_pix are in pixel units on the ref overlap grid (x=col, y=row)\n",
    "      dE_m, dN_m are in meters in the raster CRS (east, north)\n",
    "    \"\"\"\n",
    "    with rasterio.open(path_ref) as src1, rasterio.open(path_mov) as src2:\n",
    "        # Same-CRS assumption (you said EPSG:3413 for both)\n",
    "        if src1.crs != src2.crs:\n",
    "            raise ValueError(f\"CRS mismatch: ref={src1.crs}, mov={src2.crs}\")\n",
    "\n",
    "        # Compute overlap bounds in map coordinates\n",
    "        b1, b2 = src1.bounds, src2.bounds\n",
    "        left   = max(b1.left,   b2.left)\n",
    "        right  = min(b1.right,  b2.right)\n",
    "        bottom = max(b1.bottom, b2.bottom)\n",
    "        top    = min(b1.top,    b2.top)\n",
    "\n",
    "        if (left >= right) or (bottom >= top):\n",
    "            raise ValueError(\"No spatial overlap between the two DEMs.\")\n",
    "\n",
    "        # Read REF overlap (defines target grid)\n",
    "        win1 = from_bounds(left, bottom, right, top, transform=src1.transform)\n",
    "        win1 = win1.round_offsets().round_lengths()\n",
    "        dem1 = src1.read(1, window=win1, boundless=False)\n",
    "        trans1 = src1.window_transform(win1)\n",
    "\n",
    "        # Read MOV overlap on its own grid\n",
    "        win2 = from_bounds(left, bottom, right, top, transform=src2.transform)\n",
    "        win2 = win2.round_offsets().round_lengths()\n",
    "        dem2_raw = src2.read(1, window=win2, boundless=False)\n",
    "        trans2 = src2.window_transform(win2)\n",
    "\n",
    "        # Resample MOV overlap -> REF overlap grid\n",
    "        dem2_on_1 = np.empty_like(dem1, dtype=np.float32)\n",
    "        reproject(\n",
    "            source=dem2_raw,\n",
    "            destination=dem2_on_1,\n",
    "            src_transform=trans2,\n",
    "            src_crs=src2.crs,\n",
    "            dst_transform=trans1,\n",
    "            dst_crs=src1.crs,\n",
    "            resampling=Resampling.bilinear,\n",
    "            src_nodata=nodata,\n",
    "            dst_nodata=nodata,\n",
    "        )\n",
    "\n",
    "    # Prepare + masks\n",
    "    proc1, mask1 = _prepare_dem(dem1, nodata=nodata, min_elev=min_elev)\n",
    "    proc2, mask2 = _prepare_dem(dem2_on_1, nodata=nodata, min_elev=min_elev)\n",
    "\n",
    "    # Hard-mask invalid regions to suppress edge artifacts from filling\n",
    "    proc1[mask1] = 0.0\n",
    "    proc2[mask2] = 0.0\n",
    "\n",
    "    # Optionally erode valid region in REF to avoid NoData boundaries\n",
    "    valid1 = ~mask1\n",
    "    if erosion_iters and erosion_iters > 0:\n",
    "        # binary_erosion with a 3x3 footprint repeated erosion_iters times\n",
    "        for _ in range(erosion_iters):\n",
    "            valid1 = binary_erosion(valid1, footprint_rectangle((3, 3)))\n",
    "        if debug:\n",
    "            print(f\"[DEBUG] erosion_iters={erosion_iters}, valid_ref% after erosion: {100*np.mean(valid1):.2f}%\")\n",
    "\n",
    "    if debug:\n",
    "        h, w = proc1.shape\n",
    "        print(f\"[DEBUG] overlap size: (h={h}, w={w})\")\n",
    "        print(f\"[DEBUG] nodata% ref: {100*np.mean(mask1):.2f}%, mov(resampled): {100*np.mean(mask2):.2f}%\")\n",
    "        print(f\"[DEBUG] transform.a (xres): {trans1.a}, transform.e (yres): {trans1.e}\")\n",
    "\n",
    "    # SIFT\n",
    "    sift1, sift2 = SIFT(), SIFT()\n",
    "    sift1.detect_and_extract(proc1)\n",
    "    sift2.detect_and_extract(proc2)\n",
    "\n",
    "    if sift1.descriptors is None or sift2.descriptors is None:\n",
    "        raise ValueError(\"SIFT failed: descriptors are None (overlap too flat / too masked / too small).\")\n",
    "\n",
    "    if debug:\n",
    "        print(f\"[DEBUG] keypoints: ref={len(sift1.keypoints)}, mov={len(sift2.keypoints)}\")\n",
    "\n",
    "    # Match with ratio + cross-check\n",
    "    matches = match_descriptors(\n",
    "        sift1.descriptors,\n",
    "        sift2.descriptors,\n",
    "        max_ratio=max_ratio,\n",
    "        cross_check=True\n",
    "    )\n",
    "\n",
    "    if debug:\n",
    "        print(f\"[DEBUG] matches after ratio+crosscheck: {matches.shape[0]} (max_ratio={max_ratio})\")\n",
    "\n",
    "    if matches.shape[0] < 4:\n",
    "        raise ValueError(f\"Insufficient matches: {matches.shape[0]} (need >= 4).\")\n",
    "\n",
    "    # Coordinates: SIFT gives (row,col). Convert to (x,y)=(col,row)\n",
    "    src_rc = sift1.keypoints[matches[:, 0]]\n",
    "    dst_rc = sift2.keypoints[matches[:, 1]]\n",
    "    src_xy = src_rc[:, ::-1]\n",
    "    dst_xy = dst_rc[:, ::-1]\n",
    "\n",
    "    # Filter matches to those whose REF keypoints are in the eroded valid area\n",
    "    if erosion_iters and erosion_iters > 0:\n",
    "        cols = np.round(src_xy[:, 0]).astype(int)\n",
    "        rows = np.round(src_xy[:, 1]).astype(int)\n",
    "        in_bounds = (rows >= 0) & (rows < valid1.shape[0]) & (cols >= 0) & (cols < valid1.shape[1])\n",
    "        keep = np.zeros(len(rows), dtype=bool)\n",
    "        keep[in_bounds] = valid1[rows[in_bounds], cols[in_bounds]]\n",
    "        src_xy = src_xy[keep]\n",
    "        dst_xy = dst_xy[keep]\n",
    "        if debug:\n",
    "            print(f\"[DEBUG] matches after valid-area filter: {src_xy.shape[0]}\")\n",
    "\n",
    "    if src_xy.shape[0] < min_matches:\n",
    "        raise ValueError(\n",
    "            f\"Too few matches after filtering: {src_xy.shape[0]} (min_matches={min_matches}). \"\n",
    "            f\"Try reducing erosion_iters, increasing overlap, or switching to hillshade/gradient preprocessing.\"\n",
    "        )\n",
    "\n",
    "    # Translation-only robust estimate\n",
    "    tx_pix, ty_pix, keep_ratio = _robust_translation_from_matches(src_xy, dst_xy, z=3.5)\n",
    "\n",
    "    # Pixel -> map meters (EPSG:3413 is meters)\n",
    "    # trans1.a is +x pixel size; trans1.e is typically negative for north-up rasters\n",
    "    dE_m = tx_pix * trans1.a\n",
    "    dN_m = ty_pix * trans1.e  # keep sign; positive means north, negative means south (usually)\n",
    "\n",
    "    return tx_pix, ty_pix, dE_m, dN_m, int(src_xy.shape[0]), keep_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e89daba-28cd-4a07-84ba-39c474e96bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = 'C:/Users/yhqian/Downloads/QGIS_maps/PointClouds_2_Raster/ALS_L1B_20190410T164528_165720_4/ALS_L1B_20190410T164528_165720_4_1m_concave.tif'\n",
    "img2 = 'C:/Users/yhqian/Downloads/QGIS_maps/PointClouds_2_Raster/ALS_L1B_20190410T174554_181213_3/ALS_L1B_20190410T174554_181213_3_1m_concave.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f5f1011-9f9a-4aac-b69e-957a21d25ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] erosion_iters=10, valid_ref% after erosion: 13.31%\n",
      "[DEBUG] overlap size: (h=1007, w=3576)\n",
      "[DEBUG] nodata% ref: 84.20%, mov(resampled): 46.75%\n",
      "[DEBUG] transform.a (xres): 0.9999711068909402, transform.e (yres): -1.0001339622641554\n",
      "[DEBUG] keypoints: ref=2509, mov=8899\n",
      "[DEBUG] matches after ratio+crosscheck: 1252 (max_ratio=0.8)\n",
      "[DEBUG] matches after valid-area filter: 1190\n",
      "\n",
      "=== Drift (REF -> MOV) ===\n",
      "tx_pix, ty_pix: -73.0 -13.0\n",
      "dE_m, dN_m (m): -72.99789080303863 13.00174150943402\n",
      "matches used: 1190\n",
      "keep_ratio (MAD): 0.9907563025210084\n",
      "Time cost: 8.718449354171753\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "t0 = time.time()\n",
    "\n",
    "tx_pix, ty_pix, dE_m, dN_m, n_matches, keep_ratio = calculate_drift_sift_translation_only(\n",
    "    img1, img2,\n",
    "    nodata=-9999.0,\n",
    "    min_elev=-50.0,\n",
    "    max_ratio=0.8,\n",
    "    erosion_iters=10,\n",
    "    min_matches=8,\n",
    "    debug=True\n",
    ")\n",
    "print(\"\\n=== Drift (REF -> MOV) ===\")\n",
    "print(\"tx_pix, ty_pix:\", tx_pix, ty_pix)\n",
    "print(\"dE_m, dN_m (m):\", dE_m, dN_m)\n",
    "print(\"matches used:\", n_matches)\n",
    "print(\"keep_ratio (MAD):\", keep_ratio)\n",
    "\n",
    "t1 = time.time()\n",
    "print(\"Time cost:\", t1 - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "059d417f-7a54-4dd0-962f-f605bfa75e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14376435343945626"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1765.138731529644/12278.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "893bcd0b-3a68-471f-9572-cb2bf5e630b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01657312819259782"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "203.48486794871602/12278.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fe98fb6-abb7-46b6-868c-a2d260718445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.005945421958221097"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-72.99789080303863/12278.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "186b3ccb-85e8-4370-a2a7-16bca7af91cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0010589462053619497"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "13.00174150943402/12278.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a62613b-9f5b-4636-9a7a-85f8dfb7423e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (seaice_env)",
   "language": "python",
   "name": "seaice_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
